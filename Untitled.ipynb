{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4430aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70de1edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>schema_name</th>\n",
       "      <th>table_name</th>\n",
       "      <th>created_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balance_features</td>\n",
       "      <td>Среднегодовые балансы</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>prod_flake_balance</td>\n",
       "      <td>2023-08-07 12:17:23.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atm_cash_management</td>\n",
       "      <td>Рассчёт фичей для модели внесения и выдачи нал...</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>fs_atm_cash_management</td>\n",
       "      <td>2023-10-31 16:05:27.536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rates_prop</td>\n",
       "      <td>Информация по относительной разнице ставок офф...</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>fs__rates_prop</td>\n",
       "      <td>2023-10-18 15:52:50.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owner_features</td>\n",
       "      <td>Признаки по владельцам компаний</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>prod_flake_owner_features</td>\n",
       "      <td>2023-10-03 11:01:50.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>out_datamart</td>\n",
       "      <td>Профайлинги для клиентов ММБ</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>prod_flake_mmb_features</td>\n",
       "      <td>2022-12-13 20:17:30.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>anket_ul_features</td>\n",
       "      <td>Витрина фичей внешнего анкетного модуля ЮЛ для...</td>\n",
       "      <td>l_aaa_risk</td>\n",
       "      <td>anket_ul_ul_model_features</td>\n",
       "      <td>2024-07-05 17:20:41.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>goszakupka_scores</td>\n",
       "      <td>Витрина по скорам госзакупок</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>prod_flake_goszakupka_score</td>\n",
       "      <td>2024-07-08 17:53:51.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>fs_client_profile_daily_features</td>\n",
       "      <td>Ежедневные фичи по клиентам: по адресу, катего...</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>fs_client_profile_daily_features</td>\n",
       "      <td>2024-07-08 18:48:54.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>triggers_table</td>\n",
       "      <td>Признаки на основе данных НСПК МИР</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>prod_flake_nspk_features</td>\n",
       "      <td>2024-07-09 17:55:34.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>xsell_features</td>\n",
       "      <td>Признаки для модели Cross-Sell (batch)</td>\n",
       "      <td>l_profiling</td>\n",
       "      <td>fs_rsk_xsell_features</td>\n",
       "      <td>2024-07-10 12:50:30.101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  \\\n",
       "0                    balance_features   \n",
       "1                 atm_cash_management   \n",
       "2                          rates_prop   \n",
       "3                      owner_features   \n",
       "4                        out_datamart   \n",
       "..                                ...   \n",
       "235                 anket_ul_features   \n",
       "236                 goszakupka_scores   \n",
       "237  fs_client_profile_daily_features   \n",
       "238                    triggers_table   \n",
       "239                    xsell_features   \n",
       "\n",
       "                                           description  schema_name  \\\n",
       "0                                Среднегодовые балансы  l_profiling   \n",
       "1    Рассчёт фичей для модели внесения и выдачи нал...  l_profiling   \n",
       "2    Информация по относительной разнице ставок офф...  l_profiling   \n",
       "3                      Признаки по владельцам компаний  l_profiling   \n",
       "4                         Профайлинги для клиентов ММБ  l_profiling   \n",
       "..                                                 ...          ...   \n",
       "235  Витрина фичей внешнего анкетного модуля ЮЛ для...   l_aaa_risk   \n",
       "236                       Витрина по скорам госзакупок  l_profiling   \n",
       "237  Ежедневные фичи по клиентам: по адресу, катего...  l_profiling   \n",
       "238                 Признаки на основе данных НСПК МИР  l_profiling   \n",
       "239             Признаки для модели Cross-Sell (batch)  l_profiling   \n",
       "\n",
       "                           table_name        created_timestamp  \n",
       "0                  prod_flake_balance  2023-08-07 12:17:23.798  \n",
       "1              fs_atm_cash_management  2023-10-31 16:05:27.536  \n",
       "2                      fs__rates_prop  2023-10-18 15:52:50.672  \n",
       "3           prod_flake_owner_features  2023-10-03 11:01:50.374  \n",
       "4             prod_flake_mmb_features  2022-12-13 20:17:30.388  \n",
       "..                                ...                      ...  \n",
       "235        anket_ul_ul_model_features  2024-07-05 17:20:41.192  \n",
       "236       prod_flake_goszakupka_score  2024-07-08 17:53:51.660  \n",
       "237  fs_client_profile_daily_features  2024-07-08 18:48:54.344  \n",
       "238          prod_flake_nspk_features  2024-07-09 17:55:34.619  \n",
       "239             fs_rsk_xsell_features  2024-07-10 12:50:30.101  \n",
       "\n",
       "[240 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "df = pd.read_csv('datamart.csv', delimiter=';')\n",
    "# df = pd.read_excel('Перечень фичей .xlsx')\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Подготовка данных\n",
    "# df['text'] = df['name'] + ': ' + df['description']\n",
    "X = df['description'].tolist()\n",
    "y = df['name'].tolist()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3425c9a-f294-4212-8968-25fc4673f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Разделение на тренировочный и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c775e93-3e0f-48c6-a109-199359e498cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Загрузка токенизатора и модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=len(le.classes_))\n",
    "model.config.pad_token_id = tokenizer.eos_token_id  # Устанавливаем pad_token_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00bad814-2d23-42ac-a800-3e41fa1b0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация данных\n",
    "train_encodings = tokenizer(X_train, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95997184-0699-488b-92bf-9f06b1676588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание датасетов\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, y_train)\n",
    "test_dataset = Dataset(test_encodings, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76215dbd-3a4a-4d79-b48d-4db9562342a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',  # Директория для сохранения результатов обучения\n",
    "#     num_train_epochs=2,  # Количество эпох обучения\n",
    "#     per_device_train_batch_size=16,  # Размер батча для обучения на одном устройстве\n",
    "#     per_device_eval_batch_size=16,  # Размер батча для оценки на одном устройстве\n",
    "#     warmup_steps=1000,  # Количество шагов для разогрева оптимизатора\n",
    "#     weight_decay=0.03,  # Коэффициент L2-регуляризации для предотвращения переобучения\n",
    "#     logging_dir='./logs',  # Директория для сохранения логов\n",
    "#     logging_steps=10,  # Частота шагов для логирования\n",
    "#     learning_rate=5e-5,  # Скорость обучения (learning rate)\n",
    "#     gradient_accumulation_steps=4,  # Количество шагов для накопления градиентов перед обновлением весов\n",
    "#     eval_strategy=\"steps\",  # Стратегия оценки: проводить оценку каждые n шагов\n",
    "#     eval_steps=500,  # Частота шагов для проведения оценки\n",
    "#     save_strategy=\"steps\",  # Стратегия сохранения: сохранять модель каждые n шагов\n",
    "#     save_steps=500,  # Частота шагов для сохранения модели\n",
    "#     save_total_limit=2,  # Максимальное количество сохраняемых чекпоинтов\n",
    "#     load_best_model_at_end=True,  # Загружать лучшую модель в конце обучения\n",
    "#     metric_for_best_model=\"eval_loss\",  # Метрика для определения лучшей модели\n",
    "#     greater_is_better=False,  # False означает, что меньшее значение метрики лучше (например, для loss)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6263fd5-be97-4d8d-a3a5-d2c0f73c81a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=2,\n",
    "#     per_device_train_batch_size=12,  # Увеличен размер батча, если позволяет память GPU\n",
    "#     per_device_eval_batch_size=12,  # Увеличен размер батча для оценки\n",
    "#     warmup_steps=500,  # Еще уменьшено количество шагов разогрева\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=200,  # Увеличен интервал логирования\n",
    "#     learning_rate=0.01,  # Еще увеличена скорость обучения\n",
    "#     gradient_accumulation_steps=1,  # Убрано накопление градиентов для ускорения\n",
    "#     eval_strategy=\"steps\",\n",
    "#     eval_steps=1500,  # Увеличен интервал оценки\n",
    "#     save_strategy=\"steps\",\n",
    "#     save_steps=1500,  # Увеличен интервал сохранения\n",
    "#     save_total_limit=1,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"eval_loss\",\n",
    "#     greater_is_better=False,\n",
    "#     # fp16=True,  # Включено смешанное обучение с половинной точностью\n",
    "#     dataloader_num_workers=4,  # Добавлены рабочие процессы для загрузки данных\n",
    "#     disable_tqdm=False,\n",
    "#     optim=\"adamw_torch\",  # Использование оптимизированной версии AdamW\n",
    "#     # bf16=True,  # Использование bfloat16 для еще большего ускорения на поддерживаемых GPU\n",
    "#     gradient_checkpointing=True,  # Включение градиентных чекпоинтов для экономии памяти\n",
    "#     max_grad_norm=1.0,  # Ограничение нормы градиента для стабильности\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06d92880-85d3-414f-94a8-5db069254e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Настройка параметров обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.05,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    # fp16=True,  # Включено смешанное обучение с половинной точностью\n",
    "    # dataloader_num_workers=4,  # Увеличено количество рабочих процессов для загрузки данных\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "# Инициализация Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# # Обучение модели\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7739e3da-44c6-4ede-ac61-07526c41f24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 04:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>6.983500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48, training_loss=6.137722810109456, metrics={'train_runtime': 264.6754, 'train_samples_per_second': 1.451, 'train_steps_per_second': 0.181, 'total_flos': 40832222625792.0, 'train_loss': 6.137722810109456, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e9f0180-1a99-4fe0-b123-4a4bf6c06ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_gpt2_model_datamart_test240\\\\tokenizer_config.json',\n",
       " './fine_tuned_gpt2_model_datamart_test240\\\\special_tokens_map.json',\n",
       " './fine_tuned_gpt2_model_datamart_test240\\\\vocab.json',\n",
       " './fine_tuned_gpt2_model_datamart_test240\\\\merges.txt',\n",
       " './fine_tuned_gpt2_model_datamart_test240\\\\added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохранение модели\n",
    "model_path = \"./fine_tuned_gpt2_model_datamart_test240\" \n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce31316c-ea65-4750-9a08-c18fe0e874ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# # Загрузка модели и токенизатора\n",
    "# model_path = \"./fine_tuned_gpt2_model_2\"  # путь к вашей сохраненной модели\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "model_path = \"./fine_tuned_gpt2_model_datamart_test240\"\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_path, num_labels=len(le.classes_))\n",
    "model.config.pad_token_id = tokenizer.eos_token_id  # Устанавливаем pad_token_id\n",
    "\n",
    "\n",
    "\n",
    "# Убедимся, что у токенизатора есть pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de835dfb-4791-4163-9ce2-273817b7faa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ подходящих вариантов:\n",
      "1. cardtransactions_v2: 0.3517\n",
      "Признаки по карточным транзакциям\n",
      "2. cardtransactions_basic: 0.2013\n",
      "Признаки по карточным транзакциям\n",
      "3. app_vars: 0.1562\n",
      "Скрипты wsrm_features от Никиты Трифонова\n",
      "4. statement: 0.0517\n",
      "Признаки по счетам клиентов\n",
      "5. out_datamart_30: 0.0290\n",
      "Дополнительные транзакционные признаки\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# Функция для предсказания\n",
    "def predict(text, top_k=5):\n",
    "    # Токенизация входного текста\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Получение выходных данных модели\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Применение softmax для получения вероятностей\n",
    "    probabilities = F.softmax(outputs.logits, dim=1)\n",
    "    \n",
    "    # Получение top_k наиболее вероятных классов и их вероятностей\n",
    "    top_probs, top_indices = torch.topk(probabilities, k=top_k)\n",
    "    \n",
    "    # Преобразование индексов обратно в метки классов\n",
    "    top_classes = le.inverse_transform(top_indices[0].numpy())\n",
    "    \n",
    "    # Создание списка кортежей (класс, вероятность)\n",
    "    results = list(zip(top_classes, top_probs[0].numpy()))\n",
    "    \n",
    "    # Сортировка результатов по убыванию вероятности\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Пример использования\n",
    "text = \"какие таблицы использовать для расчета CLTV по клиенту\"\n",
    "top_predictions = predict(text, top_k=5)\n",
    "\n",
    "print(\"Топ подходящих вариантов:\")\n",
    "for i, (class_name, probability) in enumerate(top_predictions, 1):\n",
    "    print(f\"{i}. {class_name}: {probability:.4f}\")\n",
    "    ind = df[df['name']==class_name]['description'].index[0]\n",
    "    \n",
    "    print(df[df['name']==class_name]['description'][ind])\n",
    "    \n",
    "# у тебя в базе знаний есть информация о данных, посоветуй мне какие данные лучше выбрать для расчета модели оттока?\n",
    "# # Пример использования\n",
    "# print(predict(\"какие таблицы использовать для расчета CLTV по клиенту\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672c43-0ccf-40de-ab36-7157d3a5598c",
   "metadata": {},
   "source": [
    "### Упаковка в телегу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "85c2a7f9-8714-45ae-b549-c17ce5753ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import telebot\n",
    "from telebot import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "389e2ab5-a97d-48b1-a971-9d3d01d68057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot = telebot.TeleBot(\"6191958363:AAHb8GhePS5MDqCoh3zg-BkhDdFc11M5j4A\")\n",
    "bot = telebot.TeleBot(\"6127210948:AAEs1JKu0Lz8eFzEsHcO_TcSb9vMHKdtNIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352f817-7eaf-4a6b-8a1d-7a85a874103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@bot.message_handler(func=lambda message: True)\n",
    "def handle_message(message):\n",
    "    text = message.text\n",
    "    top_predictions = predict(text, top_k=5)\n",
    "    \n",
    "    response = \"Топ подходящих вариантов:\\n\\n\"\n",
    "    for i, (class_name, probability) in enumerate(top_predictions, 1):\n",
    "        response += f\"{i}. {class_name}: {probability:.4f}\\n\"\n",
    "        ind = df[df['name']==class_name]['description'].index[0]\n",
    "        response += f\"{df[df['name']==class_name]['description'][ind]}\\n\\n\"\n",
    "    \n",
    "    bot.reply_to(message, response)\n",
    "\n",
    "bot.polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a824209-fa80-4574-a826-41a46ee29457",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1172d839-1431-473c-b22e-d02b02e154d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "533fc7d8-28de-4327-b404-21bd70db7500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301bd8dd-4a48-485c-9bea-e4db2be919c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
